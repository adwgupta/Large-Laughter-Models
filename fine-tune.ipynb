{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library Import & Intial setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\adity\\anaconda3\\lib\\site-packages (1.13.3)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\adity\\anaconda3\\lib\\site-packages (from openai) (3.5.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\adity\\anaconda3\\lib\\site-packages (from openai) (1.8.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\adity\\anaconda3\\lib\\site-packages (from openai) (0.25.2)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\adity\\anaconda3\\lib\\site-packages (from openai) (1.10.8)\n",
      "Requirement already satisfied: sniffio in c:\\users\\adity\\anaconda3\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\adity\\anaconda3\\lib\\site-packages (from openai) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\users\\adity\\anaconda3\\lib\\site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\adity\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.4)\n",
      "Requirement already satisfied: certifi in c:\\users\\adity\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\adity\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\adity\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\adity\\anaconda3\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mounting google drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initalising OpenAI client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key = userdata.get('API_KEY'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datasets for fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smaller Dataset for Fine_Tuned Model\n",
    "SFT_training = \"Data\\FT Datasets\\SFT_training.json\"\n",
    "SFT_validation = \"Data\\FT Datasets\\SFT_validation.json\"\n",
    "\n",
    "# Larger Dataset for Large_Fine_Tuned Model\n",
    "LFT_training = \"Data\\FT Datasets\\LFT_training.json\"\n",
    "LFT_validation = \"Data\\FT Datasets\\LFT_validation.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating training and validation files for fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file-38gHvO7HnrwTWzTmT69EnGIf\n"
     ]
    }
   ],
   "source": [
    "file = SFT_training\n",
    "\n",
    "training_file = client.files.create(\n",
    "  file=open(file, \"rb\"),\n",
    "  purpose=\"fine-tune\"\n",
    ")\n",
    "\n",
    "print(training_file.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file-mY5Mnlli4fQq9xYQXf1EIUwL\n"
     ]
    }
   ],
   "source": [
    "file = SFT_validation\n",
    "\n",
    "validation_file = client.files.create(\n",
    "  file=open(file, \"rb\"),\n",
    "  purpose=\"fine-tune\"\n",
    ")\n",
    "\n",
    "print(validation_file.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating fine-tuning job to fine-tune models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FineTuningJob(id='ftjob-tNdLv1GghEEhAeUs2UNjzaED', created_at=1712853633, error=Error(code=None, message=None, param=None, error=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=5, batch_size='auto', learning_rate_multiplier='auto'), model='gpt-3.5-turbo-1106', object='fine_tuning.job', organization_id='org-zi3EJWTqmHtYGXBs91JRttD7', result_files=[], status='validating_files', trained_tokens=None, training_file='file-YYMa8xfGZScQuVN2CxtXzEt8', validation_file='file-nJkKl2YtNqyX9nwMYTFF295A', user_provided_suffix=None, seed=721140058, integrations=[])\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "\n",
    "client.fine_tuning.jobs.create(\n",
    " training_file=training_file.id,\n",
    " validation_file=validation_file.id,\n",
    " model=\"gpt-3.5-turbo-1106\",\n",
    " hyperparameters={\n",
    "   \"n_epochs\": num_epochs\n",
    " }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking fine-tuning job events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SyncCursorPage[FineTuningJob](data=[FineTuningJob(id='ftjob-IbEefZvZCQVzTVr0G5QJLwKc', created_at=1712627036, error=Error(code=None, message=None, param=None, error=None), fine_tuned_model='ft:gpt-3.5-turbo-1106:personal::9Bwhwnzw', finished_at=1712634308, hyperparameters=Hyperparameters(n_epochs=1, batch_size=5, learning_rate_multiplier=8), model='gpt-3.5-turbo-1106', object='fine_tuning.job', organization_id='org-zi3EJWTqmHtYGXBs91JRttD7', result_files=['file-2wF0QV1nKFvMow590ob7NBje'], status='succeeded', trained_tokens=421885, training_file='file-4rODnvAzBnoeLaIbStenANjy', validation_file='file-GYAggJauRFaBXk4uIXza87O9', user_provided_suffix=None, seed=72949818, integrations=[])], object='list', has_more=True)\n"
     ]
    }
   ],
   "source": [
    "client.fine_tuning.jobs.list(limit=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FineTuningJob(id='ftjob-IbEefZvZCQVzTVr0G5QJLwKc', created_at=1712627036, error=Error(code=None, message=None, param=None, error=None), fine_tuned_model='ft:gpt-3.5-turbo-1106:personal::9Bwhwnzw', finished_at=1712634308, hyperparameters=Hyperparameters(n_epochs=1, batch_size=5, learning_rate_multiplier=8), model='gpt-3.5-turbo-1106', object='fine_tuning.job', organization_id='org-zi3EJWTqmHtYGXBs91JRttD7', result_files=['file-2wF0QV1nKFvMow590ob7NBje'], status='succeeded', trained_tokens=421885, training_file='file-4rODnvAzBnoeLaIbStenANjy', validation_file='file-GYAggJauRFaBXk4uIXza87O9', user_provided_suffix=None, seed=72949818, integrations=[])\n"
     ]
    }
   ],
   "source": [
    "client.fine_tuning.jobs.retrieve(\"ftjob-IbEefZvZCQVzTVr0G5QJLwKc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SyncCursorPage[FineTuningJobEvent](data=[FineTuningJobEvent(id='ftevent-WExQYM8jldT44TjY1LYSMOPN', created_at=1712634312, level='info', message='The job has successfully completed', object='fine_tuning.job.event', data={}, type='message')], object='list', has_more=True)\n"
     ]
    }
   ],
   "source": [
    "client.fine_tuning.jobs.list_events(fine_tuning_job_id=\"ftjob-IbEefZvZCQVzTVr0G5QJLwKc\", limit=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking names for available models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\n",
      "Available models:\n",
      "dall-e-3\n",
      "whisper-1\n",
      "davinci-002\n",
      "gpt-3.5-turbo-1106\n",
      "dall-e-2\n",
      "gpt-3.5-turbo-16k\n",
      "tts-1-hd-1106\n",
      "tts-1-hd\n",
      "gpt-4\n",
      "gpt-4-turbo-2024-04-09\n",
      "gpt-4-0613\n",
      "gpt-4-vision-preview\n",
      "gpt-4-0125-preview\n",
      "gpt-3.5-turbo\n",
      "gpt-4-turbo-preview\n",
      "gpt-3.5-turbo-instruct-0914\n",
      "gpt-4-1106-preview\n",
      "gpt-3.5-turbo-0613\n",
      "gpt-3.5-turbo-instruct\n",
      "gpt-4-1106-vision-preview\n",
      "gpt-3.5-turbo-0125\n",
      "tts-1\n",
      "gpt-3.5-turbo-0301\n",
      "babbage-002\n",
      "tts-1-1106\n",
      "text-embedding-3-large\n",
      "gpt-3.5-turbo-16k-0613\n",
      "text-embedding-3-small\n",
      "text-embedding-ada-002\n",
      "gpt-4-turbo\n",
      "ft:gpt-3.5-turbo-1106:personal::906Y74tA\n",
      "ft:gpt-3.5-turbo-1106:personal::9Bwhwnzw\n",
      "ft:gpt-3.5-turbo-1106:personal::9Bwhzehp:ckpt-step-1728\n",
      "ft:gpt-3.5-turbo-1106:personal::9Bwi0f5X:ckpt-step-1729\n",
      "ft:gpt-3.5-turbo-1106:personal::9Cs8k5Hb\n",
      "ft:gpt-3.5-turbo-1106:personal::9Cs8noVc:ckpt-step-315\n",
      "ft:gpt-3.5-turbo-1106:personal::9Cs8nEDt:ckpt-step-420\n",
      "ft:gpt-3.5-turbo-1106:personal::9Cs8nJUF:ckpt-step-525\n",
      "ft:gpt-3.5-turbo-1106:personal:thesis-small:9DiVMMLB\n",
      "ft:gpt-3.5-turbo-1106:personal:thesis-small:9DiVPwHk:ckpt-step-315\n",
      "ft:gpt-3.5-turbo-1106:personal:thesis-small:9DiVPrev:ckpt-step-420\n",
      "ft:gpt-3.5-turbo-1106:personal:thesis-small:9DiVPrxC:ckpt-step-525\n",
      "ft:gpt-3.5-turbo-1106:personal:thesis-small:9DiYpfuc\n",
      "ft:gpt-3.5-turbo-1106:personal:thesis-small:9DiYroIw:ckpt-step-315\n",
      "ft:gpt-3.5-turbo-1106:personal:thesis-small:9DiYs73u:ckpt-step-420\n",
      "ft:gpt-3.5-turbo-1106:personal:thesis-small:9DiYsYcF:ckpt-step-525\n",
      "ft:gpt-3.5-turbo-1106:personal:thesis-5epoch:9DirGRan\n",
      "ft:gpt-3.5-turbo-1106:personal:thesis-5epoch:9DirI4cZ:ckpt-step-315\n",
      "ft:gpt-3.5-turbo-1106:personal:thesis-5epoch:9DirJ3Pr:ckpt-step-420\n",
      "ft:gpt-3.5-turbo-1106:personal:thesis-5epoch:9DirJtPT:ckpt-step-525\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# List available models\n",
    "models = client.models.list()\n",
    "\n",
    "# Extract model names\n",
    "model_names = [model.id for model in models]\n",
    "\n",
    "# Print model names\n",
    "print(\"Available models:\")\n",
    "for name in model_names:\n",
    "    print(name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Interaction\n",
    "\n",
    "Intialising fine-tuned model details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_topics = 20  \n",
    "num_setups = 10\n",
    "num_punchlines = 5\n",
    "\n",
    "# Model names\n",
    "baseline_model = \"gpt-3.5-turbo-0301\"\n",
    "model_2_epochs = \"ft:gpt-3.5-turbo-1106:personal::906Y74tA\"\n",
    "model_5_epochs = \"ft:gpt-3.5-turbo-1106:personal::9Cs8k5Hb\"\n",
    "over_trained_model= \"ft:gpt-3.5-turbo-1106:personal:thesis-small:9DiYpfuc\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, here are 20 topics for a joke:\n",
      "\n",
      "1. Anime\n",
      "2. Animals\n",
      "3. Books\n",
      "4. Driving\n",
      "5. Fishing\n",
      "6. Food\n",
      "7. Football\n",
      "8. Gym\n",
      "9. Law-Politics\n",
      "10. Movies\n",
      "11. Music\n",
      "12. Pickuplines\n",
      "13. Random\n",
      "14. School\n",
      "15. Science\n",
      "16. Space\n",
      "17. Superheroes\n",
      "18. Supernatural\n",
      "19. Technology\n",
      "20. Travelling\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "   model=model_5_epochs,\n",
    "   messages=[{\"role\": \"system\", \"content\": \"You are a joke writer for a comedian.\"},\n",
    "             {\"role\": \"user\", \"content\": \"From what you know about what makes a good joke, give me 10 topics to write jokes on\"}]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Topic list\n",
    "topic_1 = \"ainme, ainme characters and popular anime series\"\n",
    "topic_2 = \"animals\"\n",
    "topic_3 = \"books, writing and reading\"\n",
    "topic_4 = \"driving and cars\"\n",
    "topic_5 = \"fishing and the ocean\"\n",
    "topic_6 = \"food, chefs and cooking\"\n",
    "topic_7 = \"football/football players\"\n",
    "topic_8 = \"gym and fitness\"\n",
    "topic_9 = \"law/politics\"\n",
    "topic_10 = \"movies and acting\"\n",
    "topic_11 = \"music\"\n",
    "topic_12 = \"pickup-lines\"\n",
    "topic_13 = \"random jokes\"\n",
    "topic_14 = \"school and education\"\n",
    "topic_15 = \"science\"\n",
    "topic_16 = \"space\"\n",
    "topic_17 = \"superheroes, marvel and dc\"\n",
    "topic_18 = \"supernatural themes\"\n",
    "topic_19 = \"technology\"\n",
    "topic_20 = \"travelling\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Setups:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, here are ten setups for jokes on the topic of driving and cars\n",
      "\n",
      "1. Did you hear about the car that was sent to therapy?\n",
      "2. What makes a bad driver?\n",
      "3. What makes a great driver?\n",
      "4. What did the car tell its friend?\n",
      "5. Why did the car drive across the road?\n",
      "6. Why did the driver honk at the stop sign?\n",
      "7. How did the driver get lost?\n",
      "8. Why are car jokes not funny?\n",
      "9. What's the best way to handle bad drivers?\n",
      "10. How do you confuse a car?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "   model=model_5_epochs,\n",
    "   messages=[{\"role\": \"system\", \"content\": \"You are a joke writer for a comedian.\"},\n",
    "             {\"role\": \"user\", \"content\": \"What are good topics for jokes? Give me 20 examples.\"}]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Punchlines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_1 = \"Did you hear about the car that was sent to therapy?\"\n",
    "setup_2 = \"What makes a bad driver?\"\n",
    "setup_3 = \"What makes a great driver?\"\n",
    "setup_4 = \"What did the car tell its friend?\"\n",
    "setup_5 = \"Why did the car drive across the road?\"\n",
    "setup_6 = \"Why did the driver honk at the stop sign?\"\n",
    "setup_7 = \"How did the driver get lost?\"\n",
    "setup_8 = \"Why are car jokes not funny?\"\n",
    "setup_9 = \"What's the best way to handle bad drivers?\"\n",
    "setup_10 = \"How do you confuse a car?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup:\n",
      "Did you hear about the car that was sent to therapy?\n",
      "Punchline: It had metal problems.\n",
      "Punchline: Because it was EXHAUSTED.\n",
      "Punchline: It was having an auto body experience.\n",
      "Punchline: It had a lot of idle issues.\n",
      "Punchline: It had been a long road to recovery.\n",
      "\n",
      "Setup:\n",
      "What makes a bad driver?\n",
      "Punchline: The highway to hell.\n",
      "Punchline: Breaking instead of acceleration to avoid a wreck.\n",
      "Punchline: Asking what his 5th wheel is for.\n",
      "Punchline: Alcohol.\n",
      "Punchline: Nothing. They're just bad.\n",
      "\n",
      "Setup:\n",
      "What makes a great driver?\n",
      "Punchline: Ask Vin Diesel.\n",
      "Punchline: No witnesses.\n",
      "Punchline: Alcohol.\n",
      "Punchline: A cop in the passenger seat.\n",
      "Punchline: Red and blue lights in the rearview mirror.\n",
      "\n",
      "Setup:\n",
      "What did the car tell its friend?\n",
      "Punchline: I have metal problems.\n",
      "Punchline: I've had a road of ups and downs.\n",
      "Punchline: I'm tire-d of you.\n",
      "Punchline: Nothing, it just beeped!\n",
      "Punchline: I'm on the Highway to Hell!\n",
      "\n",
      "Setup:\n",
      "Why did the car drive across the road?\n",
      "Punchline: Because its tires were on the other side.\n",
      "Punchline: The green light told him to go.\n",
      "Punchline: Because the driver was a chicken!\n",
      "Punchline: To escape the highway to hell.\n",
      "Punchline: To get to the other road.\n",
      "\n",
      "Setup:\n",
      "Why did the driver honk?\n",
      "Punchline: To tell someone to hurry up.\n",
      "Punchline: Because he had anger steer management.\n",
      "Punchline: Because he stepped on the gas!\n",
      "Punchline: To scare the duck out of its quack coma.\n",
      "Punchline: To get to the other side. Hahaha no, that'd be ridiculous!\n",
      "\n",
      "Setup:\n",
      "How did the driver get lost?\n",
      "Punchline: He took a wrong turn.\n",
      "Punchline: He was on the highway to hell.\n",
      "Punchline: He took a 'dead end'.\n",
      "Punchline: He lost his Waze.\n",
      "Punchline: I don't know, he was following me.\n",
      "\n",
      "Setup:\n",
      "Why are car jokes not funny?\n",
      "Punchline: They always get exhausted.\n",
      "Punchline: They don't work for everyone.\n",
      "Punchline: They require maintenance.\n",
      "Punchline: Because they are tire-ing.\n",
      "Punchline: Because they're driving people away.\n",
      "\n",
      "Setup:\n",
      "What's the best way to handle bad drivers?\n",
      "Punchline: With an automatic transmission.\n",
      "Punchline: Alcohol.\n",
      "Punchline: You steal the headlights.\n",
      "Punchline: A soapbox with Velcro.\n",
      "Punchline: By the ears!\n",
      "\n",
      "Setup:\n",
      "How do you confuse a car?\n",
      "Punchline: You steal the headlights.\n",
      "Punchline: Put it in reverse and let it smoke.\n",
      "Punchline: Paint the roof and tell it a good joke.\n",
      "Punchline: The Highway to Hell.\n",
      "Punchline: Paint the doors on backward.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the number of punchlines per setup\n",
    "num_punchlines = 5\n",
    "\n",
    "# Iterate through each setup question\n",
    "for setup_num in range(1, 11):\n",
    "    # Print the current setup question\n",
    "    print(\"Setup:\", globals()[\"setup_\" + str(setup_num)])\n",
    "    \n",
    "    # Generate five punchlines for the current setup\n",
    "    for attempt in range(num_punchlines):\n",
    "        # Call the GPT-3 API to generate responses using the fine-tuned model\n",
    "        response = client.chat.completions.create(\n",
    "            model=model_2_epochs,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a joke writer for a comedian.\"},\n",
    "                {\"role\": \"user\", \"content\": \"setup: \" + globals()[\"setup_\" + str(setup_num)]}  # Next user question\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # Print the generated punchline\n",
    "        print(response.choices[0].message.content)\n",
    "    \n",
    "    # Add an empty line for separation between setups\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
